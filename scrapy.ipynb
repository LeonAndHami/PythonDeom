{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "【scrapy的使用】\n",
    "\n",
    "\n",
    "创建scrapy 项目\n",
    "scrapy startproject project_name \n",
    "\n",
    "创建爬虫\n",
    "scrapy genspider spider_name 允许爬取的范围\n",
    "\n",
    "运行爬虫 (进入到爬虫所有目录)\n",
    "scrapy crawl spider_name\n",
    "\n",
    "\n",
    "使用pipeline\n",
    "1、实现pipelines.py中的 process_item 方法\n",
    "\n",
    "2、去配置文件中开启pipeline\n",
    "ITEM_PIPELINES = {\n",
    "    'demo01.pipelines.Demo01Pipeline': 300, #数值越大数先执行\n",
    "}\n",
    "\n",
    "\n",
    "使用logging\n",
    "去配置文件中配置\n",
    "\n",
    "LOG_LEVEL = \"WARNING\"\n",
    "LOG_FILE = \"./file.log\"\t#保存路径，设置后不会再在终端中显示日志，需要使用logger\n",
    "\n",
    "\n",
    "日志的级别有\n",
    "\n",
    "CRITICAL - 严重错误\n",
    "ERROR - 一般错误\n",
    "WARNING - 警告信息\n",
    "INFO - 一般信息\n",
    "DEBUG - 调试信息  默认\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.warning('your message') 输出格式: 2019-5-20 [root] WARNING:your message，不知道在哪个文件\n",
    "\n",
    "logger = loggin.getLogger(__name__)\n",
    "logger.warning('your message') 输出格式: 2019-5-20 [your file] WARNING:your message\n",
    "\n",
    "# logging模块的设置可以通过loggin.baseConfig()来完成，百度一下参数即可\n",
    "\n",
    "\n",
    "关于scrapy中实现翻页思路：\n",
    "1、找到下一页的地址\n",
    "2、构造一人下一页url地址的request请求传给调度器\n",
    "\n",
    "next_url = response.xpath('pettern')\n",
    "while len(next_url) > 0:\n",
    "    yield scrapy.Request(next_url,callback=self.parse) # yield request对象，就可以交给scrapy引擎\n",
    "\n",
    "\n",
    "\n",
    "【scrapy.Request知识点】\n",
    "scrapy.Request(url,[,callback,method=\"GET\",headers,body,cookie,meta,dont_filter=False])\n",
    "注：中括号中的参数是可选参数\n",
    "常用参数为：\n",
    "callback：指定传入的url交给哪个解析函数去处理\n",
    "\n",
    "meta：实现在不同的解析函数中传递数据，meta默认会携带部分信息，如下载延迟、请求深度等\n",
    "\n",
    "别的解析函数中取meta\n",
    "data = response.meta\n",
    "\n",
    "dont_filter：让scrapy的去重不会过滤当前的url,scrapy默认有url去重功能，对需要重复请求的url有重要用途\n",
    "\n",
    "注意点：Request已经提供了cookie参数，cookie就不要再放到headers中去了\n",
    "\n",
    "\n",
    "【pipeline】\n",
    "pipeline中写入数据到mongodb，记得将item转为字典\n",
    "\n",
    "\n",
    "【scrapy shell】\n",
    "scrapy shell 是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试xpath\n",
    "\n",
    "用法：\n",
    "scrapy shell url\n",
    "\n",
    "response.url：当前响应的url地址\n",
    "response.request.url：当前响应的请求的url地址\n",
    "response.headers：响应头\n",
    "response.body：响应体，也就是html代码，默认是byte类型\n",
    "response.request.headers：当前响应的请求头\n",
    "\n",
    "\n",
    "【setting相关】\n",
    "\n",
    "settings中可以放一些全局变量供多个地方使用，一般全大写\n",
    "1、spider 对象里面有settings属性，可直接使用\n",
    "self.settings['key']\n",
    "self.settings.get('key','default_value')\n",
    "\n",
    "2、导入setting\n",
    "from your_project import settings\n",
    "print(settings.LOG_LEVEL)\n",
    "\n",
    "ROBOTSTXT_OBEY = True #是否遵循robots.txt中的规则\n",
    "\n",
    "CONCURRENT_REQUESTS # 并发数量\n",
    "\n",
    "DOWNLOAD_DELAY # 下载延迟\n",
    "\n",
    "COOKIES_ENABLED  # 请求是否带cookie\n",
    "\n",
    "\n",
    "\n",
    "【pipeline中的方法】\n",
    "\n",
    "    def __init__(self, mongo_url, db_name):\n",
    "        self.mongo_url = mongo_url\n",
    "        self.db_name = db_name\n",
    "\n",
    "    @classmethod\n",
    "    def from_crawler(cls, crawler):\n",
    "        return cls(mongo_url=crawler.settings.get(\"MONGO_URL\"), db_name=crawler.settings.get(\"DB_NAME\"))\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.client = MongoClient(self.mongo_url)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.context = self.db[\"users\"]\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.client.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        self.context.update({'url_token': item['url_token']}, dict(item), True)\n",
    "        return item\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
